# **ADI MAX78000 Model Training, Synthesis and Deployment** 
The following graphic shows an overview of the development flow:
<div style="text-align:center">
    <img src="images/DevelopmentFlow.png" width="700" alt="Alt text"/>
</div>
# **0) Installation**
**0.1) Prerequisites:**

<p>✔  CPU: 64-bit amd64/x86_64 “PC” with <a href="https://ubuntu.com/download/server">Ubuntu Linux 20.04 LTS or 22.04 LTS</a></p>
<p style="margin-left: 50px">The only officially supported platforms for model training are Ubuntu Linux 20.04 LTS and 22.04 LTS on amd64/x86_64, either the desktop or the server version.
On Windows 10 version 21H2 or newer, and Windows 11, after installing the Windows Subsystem for Linux (WSL2), Ubuntu Linux 20.04 or 22.04 can be used inside Windows with full CUDA acceleration. So please, <a href="https://github.com/MaximIntegratedAI/ai8x-synthesis/blob/develop/docs/WSL2.md">install Windows Subsystem for Linux</a>. </p>
<p>✔ GPU for hardware acceleration: Nvidia with <a href="https://developer.nvidia.com/cuda-toolkit-archive">CUDA 11</a></p>
<p style="margin-left: 50px">Optional but highly recommended.</p>
<p>✔ <a href="https://pytorch.org/get-started/locally/">PyTorch 1.8.1 (LTS)</a> on Python 3.8.x</p>
<p style="margin-left: 50px">In this notebook, we will use Python 3.8.11.</p>
<br>
**0.2) File System Layout:**

Once you have installed the Windows Subsystem for Linux (WSL2):

1) Create a folder for your project inside your user folder ("/home/your-username/").

2) Open Ubuntu 22.04.3 LTS in the command prompt.
3) Change to your project root:
# cd thesis
4) Git clone the 'training', 'synthesis' and 'msdk' repositories into your project folder:
# git clone --recursive "https://github.com/MaximIntegratedAI/ai8x-training/"
# git clone --recursive "https://github.com/MaximIntegratedAI/ai8x-synthesis"
# git clone --recursive "https://github.com/analogdevicesinc/msdk"
The --recursive flag tells Git to not only clone the main repository but also to recursively clone all submodules within it. 
After doing this, the resulting file system must be:
<pre>   .../thesis/ai8x-training/</pre>
<pre>   .../thesis/ai8x-synthesis/</pre>
<pre>   .../thesis/ai8x-synthesis/msdk/</pre>

<br>

**0.3) Project installation:**
*0.3.1) Free Disk Space*

A minimum of 64 GB of free disk space is recommended. Check the available space on the target file system using:
# df -kh
You should get something like:

<pre>       Filesystem      Size  Used Avail Use% Mounted on</pre>
<pre>       ...</pre>
<pre>       /dev/sda2       457G  176G  259G  41% /</pre>
<br>
*0.3.2) System Packages*

Install the following additional system packages (administrator privileges are required): 
# sudo apt-get install -y make build-essential libssl-dev zlib1g-dev \ libbz2-dev libreadline-dev libsqlite3 wget curl llvm \ libncurses5-dev libncursesw5-dev xz-utils tk-dev libffi-dev liblzma-dev \ libsndfile-dev portaudio19-dev
*0.3.3) Installing Miniconda*

Before continuing, you need to <a href="https://docs.anaconda.com/free/miniconda/#quick-command-line-install">install Miniconda</a>, which is a small bootstrap version of Anaconda that includes only conda, Python, the packages they both depend on, and a small number of other useful packages (like pip, zlib, and a few others). If you need more packages, use the conda install command to install from thousands of packages available by default in Anaconda’s public repo, or from other channels, like conda-forge or bioconda.
<br>
<br>
*0.3.4) Repository Branches*

By default, the "default branch" (*develop*) is checked out. This branch is the most frequently updated branch and it contains the latest improvements to the project. To switch to the "main branch" that is updated less frequently, but may be more stable, use the following command:
# git checkout main
or
# git checkout master
*0.3.5) Creating the Virtual Environments*

Once you have installed Miniconda, change to the "ai8x-training" folder:
# cd ai8x-training
Create and activate a virtual environment (i.e., "max") that uses Python 3.8.11:
# conda create --name max python=3.8.11
# conda activate max
<p id="updates">Then continue with:</p>
# pip3 install -U pip wheel setuptools
The next step depends on whether the system uses CUDA 11.x, or not:
# **** For CUDA 11.x on Linux, including WSL2: ****
# pip3 install -r requirements-cu11.txt

# **** For CUDA 11.x on native Windows: ****
# pip3 install -r requirements-win-cu11.txt

# **** For all other systems, including macOS, and CUDA 10.2 on Linux: ****
# pip3 install -U -r requirements.txt
For minor updates, pull the latest code and install the updated wheels:
# git pull
# git submodule update --init
# pip3 install -U pip setuptools
# pip3 install -U -r requirements.txt
Now, do the same for synthesis. Deactivate the "ai8x-training" environment, change to the "ai8x-synthesis" folder and create a second virtual environment (i.e., "synthesis") that also uses Python 3.8.11:
# conda deactivate
# cd ..
# conda create --name synthesis python=3.8.11
# conda activate synthesis
For all systems, continue with:
# pip3 install -U pip setuptools
# pip3 install -r requirements.txt
Installation is now complete. It is important to remember to activate the proper Python virtual environment when switching between projects. If scripts begin failing in a previously working environment, the cause might be that the incorrect virtual environment is active or that no virtual environment has been activated.
<br>
<br>
<p id="environmentActivation" style="font-weight: bold;">How to activate a Python virtual environment within the notebook:</p>

1) Click on "Select Kernel" in the top right corner of VS Code
2) Choose the "Select another Kernel" option
3) Select "Python Environments..."
4) Choose the desired environment
<br>
<br>
<br>
<p id="MSDKInstallation" style="font-weight:bold">0.4) Install the Embeded Software Development Kit (MSDK):</p>
The Software Development Kit (MSDK) for MAX78000 and MAX78002 is used to compile, flash, and debug the output of the ai8x-synthesis (“izer”) tool. It also enables general software development for the microcontroller cores of the MAX78000 and MAX78002.
<p>An automatic installer is available for the MSDK. Instructions for downloading, installing, and getting started with the MSDK’s supported development environments are found in the <a href="https://analogdevicesinc.github.io/msdk/USERGUIDE/">MSDK User Guide</a>.</p>
<br>
<br>
# **1) Training**
⚠️ Activate the training Python virtual environment. See <a href="#environmentActivation">how to activate an environment within the notebook</a>.
**1.1) Dataset + Data Loader**
The first step for training is to create the **data loader**, whose primary role is to manage the data feeding into the model. 
<p>A lot of effort in solving any machine learning problem goes into preparing the data. PyTorch provides many tools to make data loading easy and hopefully, to make your code more readable. To run this tutorial, please make sure the following packages are installed:</p>
# pip3 show sickit-image
# pip3 show pandas
and if they are not, install them by executing:
# pip3 install sickit-image
# pip3 install pandas
<p>The steps to develop a data loader are the following:</p>
<p style="margin-left:50px">• First see <a href="https://pytorch.org/tutorials/beginner/data_loading_tutorial.html">how to develop a data loader in PyTorch</a>.</p>
<p style="margin-left:50px">• The data loader must include a loader function, for example mnist_get_datasets(data, load_train=True, load_test=True). data is a tuple of the specified data directory and the program arguments, and the two bools specify whether training and/or test data should be loaded.</p>
<p style="margin-left:50px">• The data loader is expected to download and preprocess the datasets as needed and install everything in the specified location.</p>
<p style="margin-left:50px">• The loader returns a tuple of two PyTorch Datasets for training and test data.</p>
<p>This is explained in more depth in the application note <a href="https://www.analog.com/en/resources/app-notes/data-loader-design-for-max78000-model-training.html">Data Loader Design for MAX78000 Model Training</a>. The file must include the datasets data structure that describes the dataset and points to the new loader. Datasets can list multiple datasets in the same file.</p> 
An example for this is *TOF.py*, which you can find in the repository in the *tof/ai8x-training/datasets/* folder. There is also a template you can use in the folder *templates/ai8x-training/datasets/*.

Finally, place the new dataset file into your *ai8x-training/datasets/* directory.</p>
<br>
**1.2) Training Software**
The main training software is *train.py*, it drives the training aspects, including model creation, checkpointing, model save, and status display. 

However, this file lacks some parts of the code for the representation of the confusion matrix and the validation loss. Substitute the original file by the *train.py* version in the repository (in *templates/ai8x-training/*). Once you have done this, you need to specify the classes for your dataset where the confusion matrix is displayed (at the end of the 'test' function).
<pre><div style="padding:10px; align-items:center; justify-content:center; background-color: #0a0a0a; width:850px; font-size:15px"># Plot the confusion matrix<br>from sklearn.metrics import ConfusionMatrixDisplay<br>import matplotlib.pyplot as plt<br><br># Labels<br>labels = [ ]    # SPECIFY HERE THE OUTPUT CLASSES (i.e., labels = ['Background','Robot'])<br># Using ConfusionMatrixDisplay to plot the confusion matrix<br>disp = ConfusionMatrixDisplay(confusion_matrix=conf_matrix, display_labels=labels)<br><br># Plotting<br>disp.plot(cmap='PuBuGn', values_format='d')<br>plt.title('Confusion Matrix')<br>plt.show()</div></pre>
<br>
**1.3) Model creation**
To support evaluation of the quantized model using PyTorch, the model must be instantiated and initialized using all parameters supplied by *train.py*, and the parameters must be passed to the individual nn.Modules. The file must include the models data structure that describes the model. models can list multiple models in the same file.

<p>For each model, three fields are required in the data structure:</p>

<p style="margin-left: 50px;">1) The "name" field assigns a name to the model for discovery by train.py (i.e., "ai85net") and the name must match a function that instantiates the model. Note: The name must be unique.</p>
<p style="margin-left: 50px;">2) The "min_input" field describes the minimum width for 2D models, it is typically 1 (when the input W dimension is smaller than min_input, it is padded to min_input).</p>
<p style="margin-left: 50px;">3) The "dim" field is either 1 (the model handles 1D inputs) or 2 (the model handles 2D inputs).</p>

An example for this is *ai85net.py*, which you can find in the repository in the *tof/ai8x-training/models/* folder. There is also a template you can use in the folder *templates/ai8x-training/models/*.
<br>
<br>
Place the new model file into your *ai8x-training/models/* directory. This way, *train.py* will be able to discover and use the new model by specifying "--model *modelname*".
<br>
<br>
**1.4) Checkpointing**
To launch the training, run the following code. This script will place checkpoint files into the *logs/* directory. 
# Specify the name of your dataset and model
!cd ai8x-training && python train.py --lr 0.1 --optimizer SGD --epochs 78 --deterministic --compress policies/schedule.yaml --model ai85net5 --dataset TOF  --confusion --param-hist --pr-curves --embedding --device MAX78000 "$@"
Here is a breakdown of every argument so that you can change them according to your needs:

<table>
    <tr>
        <th>Parameter</th>
        <th>Description</th>
    </tr>
    <tr>
        <td><strong>--lr</strong></td>
        <td>Specifies the learning rate for the optimizer during training. It controls how much to change the model in response to the estimated error each time the model weights are updated. Consider using a smaller learning rate if the training process is unstable or a larger one if the training is too slow. Typically a float (e.g., 0.01, 0.001).</td>
    </tr>
    <tr>
        <td><strong>--optimizer</strong></td>
        <td>Sets the optimizer for training the model. "SGD" stands for Stochastic Gradient Descent (a popular optimization algorithm). Different optimizers like Adam, RMSprop, or AdamW might converge faster or reach better minima for your specific problem.</td>
    </tr>
    <tr>
        <td><strong>--epochs</strong></td>
        <td>Determines the number of times the entire dataset is passed forward and backward through the neural network. It's an integer value (e.g., 10, 100). If your model has not yet converged (i.e., if the validation performance continues to improve without overfitting), consider increasing the number of epochs. Be cautious of overfitting, though; always monitor validation loss alongside training loss.</td>
    </tr>
    <tr>
        <td><strong>--deterministic</strong></td>
        <td>Ensures that every run of the script is deterministic (i.e., produces the same results every time it's run with the same parameters and data). It's a flag, so its presence enables the behavior.</td>
    </tr>
    <tr>
        <td><strong>--compress</strong></td>
        <td>Likely refers to applying a compression policy to the model from a specified YAML file, which could include techniques like pruning or quantization. Its value must be the path to a YAML file that defines the compression policy.</td>
    </tr>
    <tr>
        <td><strong>--model</strong></td>
        <td>Specifies the model architecture to use.</td>
    </tr>
    <tr>
        <td><strong>--dataset</strong></td>
        <td>Indicates which dataset to use for training the model.</td>
    </tr>
    <tr>
        <td><strong>--confusion</strong></td>
        <td>Generates a confusion matrix. It's a flag, so its presence enables the behaviour.</td>
    </tr>
    <tr>
        <td><strong>--param-hist</strong></td>
        <td>Records the history of parameter changes over training epochs. It's a flag, so its presence enables the behaviour.</td>
    </tr>
    <tr>
        <td><strong>--pr-curves</strong></td>
        <td>Generates precision-recall curves, which are useful for showing the trade-off between precision and recall for different threshold settings. It's a flag, so its presence enables the behaviour.</td>
    </tr>
    <tr>
        <td><strong>--embedding</strong></td>
        <td>Enables the generation of embeddings for the data, useful for visualization or for use in tasks like transfer learning. It's a flag, so its presence enables the behaviour.</td>
    </tr>
    <tr>
        <td><strong>--device</strong></td>
        <td>Specifies the hardware device (in this case, a MAX78000) on which the model should be trained.</td>
    </tr>
    <tr>
        <td><strong>"$@"</strong></td>
        <td>This is used in shell scripts to pass all other arguments that are provided to the script.</td>
    </tr>
</table>
Since training can take a significant amount of time, the training script does not overwrite any weights previously produced. Results are placed in sub-directories under *logs/* named with the date and time when training began. The latest results are always soft-linked to by *latest-log_dir* and *latest_log_file*.

⚠️ If you get an error, check that the data loader wrote the data correclty to a zip file in the *ai8x-training/data/* directory, and if it didn't, you can copy it manually.
<br>
<br>
# **2) Synthesis**
⚠️ Activate the synthesis Python virtual environment. See <a href="#environmentActivation">how to activate an environment within the notebook</a>.
**2.1) Network Loader (AI8Xize)**
The network loader creates the C code that programs the MAX78000/MAX78002 (for embedded execution, or RTL simulation). Additionally, the generated code contains sample input data and the expected output for the sample, as well as code that verifies the expected output.
The *ai8xize.py* program needs three inputs:

<p style="margin-left: 40px">1) A quantized checkpoint file, generated by the MAX78000/MAX78002 model quantization program quantize.py.</p>
<p style="margin-left: 40px">2) A YAML description of the network.</p>
<p style="margin-left: 40px">3) A NumPy “pickle” .npy file with sample input data.</p>
<br>
**1. Quantized Checkpoint File**
There are two main approaches to quantization: quantization-aware training and post-training quantization. The MAX78000/MAX78002 supports both approaches.

In both cases, the *quantize.py* software quantizes an existing PyTorch checkpoint file and writes out a new PyTorch checkpoint file that can then be used to evaluate the quality of the quantized network, using the same PyTorch framework used for training. The same new quantized checkpoint file will also be used to feed the Network Loader.

However, Quantization-Aware Training is the better performing approach, so it's the one we are going to use.
✲ *Quantization-Aware Training*

The input checkpoint to *quantize.py* is *qat_best.pth.tar* (the best QAT epoch’s checkpoint). You can find this file in the *logs/* directory in the training project folder, specifically in the sub-directory under *logs/* named with the date and time when last training began.

Copy this file (*qat_best.pth.tar*) to the *ai8x-synthesis/logs/* directory.

Afterwards, run the following code (the output will be *proj_q8.pth.tar*):
!cd ai8x-synthesis && python quantize.py logs/qat_best.pth.tar logs/proj_q8.pth.tar --device MAX78000
**2. YAML Network Descriptor File**
Here is a <a href="https://github.com/analogdevicesinc/MaximAI_Documentation/blob/main/Guides/YAML%20Quickstart.md">quick start guide</a> on the structure of the YAML network descriptor file.

Place the new YAML file in your *networks/* directory (i.e., *ai8x-synthesis/networks/TOF.yaml*)
<br>
<br>
**3. NumPy “pickle” .npy file**

To generate a random sample input from Training Data, run the followig code:

⚠️ (First, activate the training Python virtual environment. See <a href="#environmentActivation">how to activate an environment within the notebook</a>.)
# Specify the name of your dataset and model
!cd ai8x-training && python train.py --model ai85net5 --dataset TOF --confusion --evaluate --exp-load-weights-from ../ai8x-synthesis/trained/ai85-tof-qat8-q.pth.tar -8 --device MAX78000 "$@" --save-sample 10
The argument "--save-sample 10" is used to save the sample (the index 10 is arbitrary, but it must be smaller than the batch size. If manual visual verification is desired, it is a good idea to pick a sample where the quantized model computes the correct answer).

This code generates a file named *sample_mnist.npy* into the *ai8x-training/* directory. Copy this file to the *ai8x-synthesis/tests/* directory.
<br>
<br>
__
Finally, you can execute the following code to generate an embedded MAX78000 demo in the *ai8x-synthesis/demos/ai85-yourdataset/* folder.

⚠️ (Activate the synthesis Python virtual environment again. See <a href="#environmentActivation">how to activate an environment within the notebook</a>.)
# Specify the "--prefix" and the "--config-file"
!cd ai8x-synthesis && python ai8xize.py --verbose --test-dir demos --prefix ai85-TOF --checkpoint-file logs/proj_q8.pth.tar --config-file networks/TOF.yaml --device MAX78000 --compact-data --softmax --overwrite --timer 0
Here is a breakdown of every argument so that you can change them according to your needs:

<table>
    <tr>
        <th>Parameter</th>
        <th>Description</th>
    </tr>
    <tr>
        <td><strong>--verbose</strong></td>
        <td>This parameter increases the verbosity of the command's output. It means the script will provide more detailed information about what it is doing as it runs, which can be helpful for debugging or understanding the process better.</td>
    </tr>
    <tr>
        <td><strong>--test-dir</strong></td>
        <td>Specifies the directory where the test data is located. The script will use files from this directory to perform testing.</td>
    </tr>
    <tr>
        <td><strong>--prefix</strong></td>
        <td>Sets a prefix for generated files.</td>
    </tr>
    <tr>
        <td><strong>--checkpoint-file</strong></td>
        <td>Specifies the path to the checkpoint file that contains the trained model weights.</td>
    </tr>
    <tr>
        <td><strong>--config-file</strong></td>
        <td>Points to a configuration file that defines various parameters or settings for the model and its deployment.</td>
    </tr>
    <tr>
        <td><strong>--device</strong></td>
        <td>Specifies the target device for the deployment. In our case the MAX78000.</td>
    </tr>
    <tr>
        <td><strong>--compact-data</strong></td>
        <td>This flag indicates that the data used during the process will be in a compact format, optimized for speed or memory usage.</td>
    </tr>
    <tr>
        <td><strong>--softmax</strong></td>
        <td>Instructs the script to apply a softmax function to the output layer of the neural network.</td>
    </tr>
    <tr>
        <td><strong>--overwrite</strong></td>
        <td>This flag allows the script to overwrite existing files without asking for confirmation.</td>
    </tr>
</table>
The generated C code comprises the following files:

<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>File Information Table</title>
<style>
    table {
        border-collapse: collapse;
    }
    th, td {
        border: 1px solid black;
        padding: 8px;
        text-align: left;
        white-space: nowrap;
    }
</style>
</head>
<body>

<table>
    <tr>
        <th>File name</th>
        <th>Source</th>
        <th>Project specific?</th>
        <th>Model/weights change?</th>
    </tr>
    <tr>
        <td>Makefile*</td>
        <td>template(s) in assets/embedded-</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>cnn.c</td>
        <td>generated</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>cnn.h</td>
        <td>template in assets/device-all</td>
        <td>Yes</td>
        <td>Yes</td>
    </tr>
    <tr>
        <td>weights.h</td>
        <td>generated</td>
        <td>Yes</td>
        <td>Yes</td>
    </tr>
    <tr>
        <td>log.txt</td>
        <td>generated</td>
        <td>Yes</td>
        <td>Yes</td>
    </tr>
    <tr>
        <td>main.c</td>
        <td>generated</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>sampledata.h</td>
        <td>generated</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>sampleoutput.h</td>
        <td>generated</td>
        <td>Yes</td>
        <td>Yes</td>
    </tr>
    <tr>
        <td>softmax.c</td>
        <td>assets/device-all</td>
        <td>No</td>
        <td>No</td>
    </tr>
    <tr>
        <td>model.launch</td>
        <td>template in assets/eclipse</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>.cproject</td>
        <td>template in assets/eclipse</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>.project</td>
        <td>template in assets/eclipse</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>.settings/*</td>
        <td>templates in assets/eclipse/.settings</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
    <tr>
        <td>.vscode/*</td>
        <td>generated and templates in assets/vscode</td>
        <td>Yes</td>
        <td>No</td>
    </tr>
</table>

</body>
</html>
<br>

# **3) Deployment**
Once you have generated the C code, you can start with the deployment. This section walks through setup, opening, and running the project in VS Code. 

As explained in the <a href="#MSDKInstallation">Installation section</a>, you will need to install the Software Development Kit for MAX78000 (MSDK). For the following steps, ONLY if you installed MSDK on Windows, you will need to copy the C code folder (located in the *ai8x-synthesis/demos/* directory) to Windows (i.e., */Documents/your_folder*).
**3.1.) Setup (VS Code)**

The setup below needs to be done only once per installation.

1) Download and install Visual Studio Code for your OS <a href="https://code.visualstudio.com/Download">here</a>.
2) Launch Visual Studio Code.
3) Install the Microsoft <a href="https://marketplace.visualstudio.com/items?itemName=ms-vscode.cpptools">C/C++ extension</a>.
4) Install the <a href="https://marketplace.visualstudio.com/items?itemName=marus25.cortex-debug">Cortex-Debug extension</a>
5) Use CTRL + SHIFT + P (or COMMAND + SHIFT + P on MacOS) to open the developer prompt.
6) Type "open user settings" and select the "Preferences: Open User Settings (JSON)" option.
7) Set the "MAXIM_PATH" to the absolute path of your MSDK Installation. For example, you might set '*"MAXIM_PATH": "C:/MaximSDK"*' on Windows and '*"MAXIM_PATH": "/home/username/MaximSDK"*' on Ubuntu/MacOS.
**3.2.) Building and Running a Project (VS Code)**

1) Launch Visual Studio Code.
2) Select File -> Open Folder... and navigate to your project folder.
3) Set the Board Support Package to match your evaluation platform. In VS Code, this is done by editing the *.vscode/settings.json* file and setting the "board" project configuration option.
<pre><div style="padding:10px; align-items:center; justify-content:center; background-color: #0a0a0a; width:190px; font-size:15px">"target": "MAX78000"<br>"board": "EvKit_V1"</div></pre>

4) Reload the VS Code window (after chaning any options in *settings.json*, a reload is necessary to force it ro re-index VS Code's Intellisense engine). This is done by pressing the shortcut CTRL + SHIFT + P (or COMMAND + SHIFT + P on MacOS) to open the developer prompt and choosing "Developer: Reload Window".
5) Press the shortcut CTRL + SHIFT + B to open the available Build Tasks (alternatively navigate to Terminal -> Run Build task...)
6) Run the "build" task to compile the project for the configured Target Microcontroller and BSP.
7) Connect a debug adapter between the host PC and the evaluation platform. Detailed instructions on this hardware setup can be found in the <a href="https://www.analog.com/media/en/technical-documentation/data-sheets/MAX78000FTHR.pdf">evaluation platform's Datasheet</a> and <a href="https://github.com/analogdevicesinc/MaximAI_Documentation/blob/main/MAX78000_Feather/README.md">Quick-Start Guide</a>.
8) Run the flash build task. Running this task will automatically build the project if needed, flash the program binary, and halt the program execution to await a debugger connection.
9) Open the Serial Monitor, select the port and start monitoring.

You should obtain something like this:

<div style="text-align:left; font-size:13px; border: 1px solid grey; max-width: 225px; padding:10px">
    ---- Opened the serial port COM11 ----
    
Waiting...

*** CNN Inference Test tof ***

*** PASS ***

Approximate inference time: 101 us

Classification results:

[ -39718] -> Class 0: 3.0%

[  39336] -> Class 1: 97.0%
</div>

where you can see the approximate inference time of your model in microseconds (us), as well as the classification results.

